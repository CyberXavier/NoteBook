卷积神经网络基础

## 3-2基本组成单元

### 什么是卷积神经网？

* 以卷积结构为主，搭建起来的深度网络
  * 将图片作为网络的输入，自动提取特征（参数优化后正向传播得到不同维度的向量{10维度、20、100、1024等}），并且对图片的变形（如平移，比例缩放、倾斜）等具有高度不变形

### 卷积神经网络的重要组成单元

* 卷积层
* 池化层
* 激活层
* BN层
* BP层
* FC层（全连接层）
* LOSS层
* 其他层



## 3-3卷积运算的定义

### 卷积的基本定义

* 对图像和滤波矩阵（卷积核）做内积（逐个元素相乘再求和）的操作

  * 滤波器：使用滤波器可以提取图像不同的特征。例如：可以通过滤波器对图像进行降噪，去掉一些高频信号保留一些低频信号或者去掉低频保留高频等等。不同的滤波器可以完成不同的操作（例如：图像降噪下可以采用均值滤波器、图像边缘提取也可以用到其他滤波器）

  * 每一种卷积对应一种特征，卷积过程图如下：
  * <img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-3卷积过程.PNG" alt="3-3卷积过程" style="zoom: 80%;" />
    * 卷积区域：对图像进行水平与垂直方向的扫描，每次卷积区域的大小都与卷积核大小保持一致。
      * 此外卷积区域的选择还应考虑在实际过程中对于图像像素点的位置是否敏感（例如分类任务不敏感就可以通过上图的（1，1）的位置开始）
      * 对于像素点的位置敏感，我们就需要对图像进行padding，第一个卷积核的位置就要从（0，0）开始。这个时候所选择的卷积区域有一部分在图像外，没有值，这个时候可以通过填充0来进行接下来的运算。这样通过卷积运算之后就可以保证得到的特征图大小与原图相同
    * 卷积运算：内积（对相同位置的值相乘再相加 ）
    * 卷积后的特征值：-8为卷积后的一个特征值

  * im2col实现卷积运算
    * 通常进行卷积运算的内部实现的时候，并不会像上面那样通过水平和垂直方向的遍历来完成卷积运算。实际上会将图像转换成矢量运算，直接通过矩阵相乘的方法，直接得到卷积运算的结果。
    * im2col方法：将图像重构，重构之后就可以直接通过矩阵相乘的方法来完成卷积运算
    * ***im2col实现方法？？？？？？？？***



## 3-4卷积的重要参数以及卷积核

### 卷积中的重要参数

> * 卷积核
> * 步长
> * pad
> * num output
> * 其他

---

* 卷积核
  * 最常用的是2D卷积核（k_w × k_h），其他还有1D、3D的卷积核
  * 权重和偏置项
    * 例如：Y = WX + b	，其中W是权重，X是输入数据，b为偏置项
    * 如果W是1×n的矩阵，X是n×1的矩阵那么：卷积运算    --->    Y = WX
  * 常用的卷积核：1×1，3×3，5×5，7×7
    * 为什么卷积核都选择奇数矩阵？
      * 可以保护位置信息（有中心点所以通过卷积运算之后保证了卷积之后的点和原始图像上点的位置关系是一 一对应的，这个时候这些点的语义信息就是一致的，**在解决和这些点的语义信息相关的任务时这些信息有着极大的作用**）
      * padding时对称（如下图5×5的矩阵）
      * <img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-4奇数矩阵原因.PNG" alt="3-4奇数矩阵原因" style="zoom: 33%;" />



## 3-5权值共享与局部连接

### 卷积中的重要参数

* 卷积  --  权值共享与局部连接（局部感受野 / 局部感知）

  * 卷积运算作用在局部，作用域可称为局部感受野
  * Feature map使用同一个卷积核运算后得到一种特征（一种特征就是输出的一个Feature map）
  * 多种特征采用多个卷积核（输出的Chanel的数量---numout）
  * 权值共享：卷积运算中所有的局部区域对应的卷积核的参数都是相同的
    * 这样可以极大减少参数的数量以及降低过拟合问题的概率

  * 局部连接：从神经网络层和层的连接关系来看，输入层和输出层（隐藏层）就是局部连接的    ---    也就是输入层中的一个区域对应的是输出层中的一个点（可见3-3卷积过程图）
  * （扩展）全连接：也就是输入层中所有的点对应的是输出层中的一个点
    * 这样的话参数量过大容易产生过拟合



## 3-6卷积核与感受野

### 卷积中的重要参数

* 卷积核与感受野

  * 使用多个更小的卷积核解决更大的感受野可以减少参数量以及计算量

    * 2个3×3（卷积核 ）= 1个5×5（感受野）
      * 2个3×3的卷积核：18个参数。而1个5×5的卷积核：25个参数

    * 3个3×3（卷积核）= 1个7×7（感受野）
      * 3个3×3的卷积核：27个参数。1个7×7的卷积核：49个参数
* 卷积核
  * 什么是channel？
    * 最初输入的图片样本的 `channels` ，取决于图片类型，比如RGB；如下图，假设现有一个为 6×6×3的图片样本，使用 3×3×3 的卷积核（filter）进行卷积操作。此时输入图片的 `channels` 为 3，而**卷积核中**的 `in_channels` 与 需要进行卷积操作的数据的 `channels` 一致（这里就是图片样本，为3）。
    * ![3-6channel解释示例](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-6channel解释示例.png)
    * 卷积操作完成后输出的 `out_channels` ，取决于卷积核的数量。此时的 `out_channels` 也会作为下一次卷积时的卷积核的 `in_channels`；
    * 卷积核中的 `in_channels` ，刚刚2中已经说了，就是上一次卷积的 `out_channels` ，如果是第一次做卷积，就是1中样本图片的 `channels` 。
  * 如何计算卷积参数量（卷积核所需要的参数量）
    * （k_w × k_h × in_channel + 1）× out_channel
      * （k_w × k_h）：卷积核的大小也就是原图像中局部区域的大小
  * 如何计算卷积的计算量
    * ln_w × ln_h × (k_w × k_h × in_channel + 1) × out_channel
      * (k_w × k_h × in_channel + 1)：进行一个局部区域完成卷积的计算量
      * ln_w × ln_h：a.对于整个图像而言大小是`ln_w × ln_h`个像素点，总共需要对这么多的点进行卷积运算；b.`ln_w × ln_h`也可以是输出的特征图的像素点的个数，这样计算会更加精确
  * 计算下一层维度
    * (n + 2p - f) / s + 1   【n:上一层维度，p：padding大小，f：卷积核大小，s：步幅】



## 3-7步长与Pad

* 步长（stride）
  * 下采样的过程
  * output size：（N-F）/ stride + 1    `(N：多少阶的矩阵、F：卷积核的阶数)`
    * ```e.g.N=7,F=3:```
    * `stride=1 => (7-3)/1+1 = 5`
    * `stride=2 => (7-3)/2+1 = 3`
    * `stride=3 => (7-3)/3+1 = 2.33`***（在下采样过程中出现小数会通过取整的办法继续采样【因为不存在2.33×2.33的矩阵只有整数倍的】这样就导致精确度降低了）***
  * 输出Feature Map的大小如何变化
  * 参数量和计算量

* Pad
  * 确保Feature Map整数倍变化，对尺度相关的任务及其重要
  * 参数量与计算量



## 3-9池化层

### 池化的基本概念

* **池化**：对输入的特征图进行压缩
  * 使特征图变小，简化网络计算复杂度
    * 特征图从4×4变为2×2，当我们使用相同的卷积核的时候计算量明显下降
  * 进行特征压缩，提取主要特征
    * 我们在压缩特征图片时，会提取主要特征。（例如：下图中提取max pool最大值）
  * 增大感受野
    * 压缩后每一个特征图上的值都对应原图上一个更大的感受野，当使用压缩图进行卷积运算时，相同的卷积核所对应的感受野也会变得更大

![3-9池化](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-9池化.PNG)

* **池化层**

  * 常见的池化策略
    * 最大池化（Max Pooling）
    * 平均池化（average Pooling）
    * 随机池化（stochastic Pooling）

  * `池化层没有参数`也就是说在进行反向传播算法（BP）时是不会进行参数优化，可以直接理解为一种运算（完成的就是对当前特征图进行下采样）



## 3-10激活层

* **什么是激活层？**
  * 通过激活函数给卷积神经网络增加非线性变化的层（卷积是一种线性变化，当我们遇到某种非线性的问题需要求解时显然使用若干次卷积运算任然是线性运算，不能求出更加精确的值）

* **激活函数**
  * Sigmoid
  * Tanh
  * ReLU
  * ELU
  * Maxout
  * Softplus
  * Softsign

* **激活函数的特点**
  * 非线性
  * 单调的
  * 可微的
  * 有范围的

### 激活函数的概念

* sigmoid函数

  * 表达式：Y = 1/(1+e^-x)
  * 输出不已0为中心分界，而已0.5为中心
    * <u>~~**影响后续模型参数调优的时候梯度下降法不会沿着梯度最大的方向进行**~~</u>
  * 梯度弥散/梯度饱和
    * 在x较大或者较小的情况下函数的导数趋近与0

  * 函数中含有指数计算量变大
    * 很少用于卷积神经网络中间层
  * 取值范围（0，1）
    * 常用于卷积神经网络的输出层，将值映射称概率返回。
  * RNN（循环神经网络用的多）

* **tanh（双曲正切函数）**

  * 表达式：Tanh(x) = (e^x - e^-x) / (e^x + e^-x)
  * 完全可微分，反对称，对称中心在原点
  * 指数运算
    * 很少用于卷积神经网络中间层

  * 取值范围（-1，1）
  * RNN（循环神经网络用的多）

* **ReLU（修正线性单元 --- Rectified Linear Unit）**
  * 表达式：当x<=0：f(x) = 0 ；当x>0：f(x) = x
  * 当输入为正数时，不存在梯度饱和的问题，并且收敛速度也比较快。
  * 当输入为负数时，容易引起ReLU死亡
    * 所以我们需要通过调节学习率来避免这个问题
  * 保留了step函数的生物学启发（只有当数值超过一定的阈值时神经元才会激活）



## 3-11 BatchNorm层

* **基本概念**
  * BN是一种将数据强制规范化的方法，通过一定手段把每层神经网络任意神经元的输入值的数据分布强行拉回到均值为0，方差为1的正态分布上
  * 为什么要引入BN层对数据强行规范化处理？
    * 输入的数据分布具有不可控性，每一层的数据分布都是有差异的
    * 每一层的数据在经过BP算法都会改变相应层的参数，参数的改变意味着这一层的输入输出会发生变化，导致数据分布的不可控
    * ***这些原因对于网络的收敛非常不利***所以加入了BN层对数据规范化
  * 规范化过程如下图：

![3-11BN规范化过程](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-11BN规范化过程.PNG)

> 输入：输入数据x1..xm（这些数据是准备进入激活函数的数据） 
> 计算过程中可以看到, 
> 1.求数据均值； 
> 2.求数据方差； 
> 3.数据进行标准化（个人认为称作正态化也可以） 
> 4.训练参数γ，β 
> 5.输出y通过γ与β的线性变换得到新的值 



* **BN层优点**
  * 对数据添加了约束，使得数据满足（0，1）的正态分布。即对参数的解空间进行了空间限定。***相当于对于模型添加了正则项，就可以去掉像dropout和L2正则项参数（正则化的约束主要用来解决网络过拟合问题）***。换句话说：BatchNorm层减少了过拟合的风险
  * 减少了对学习率的要求，网络收敛速度也会变快
    * 因为数据存在规律了，解空间也变小了
  * 可以不用在使用局部响应归一化，BN本身就是一种归一化网络（局部相应归一化——ALexNet）
  * 破坏原来数据的分布，使得模型变得更简单，一定程度上缓解了过拟合的问题



* 正则化为什么能够解决过拟合问题？：
  **Regularization通过对权重值的修正，使得权重不会偏离太大，从而减少过拟合的产生**

* [正则化讲解](https://howiexue.blog.csdn.net/article/details/104271157)

* BatchNormalization是对数据差异性进行处理的方法（归一化处理）

  > **模型网络中使用是在数据经过卷积层之后，到激活函数之前，加入Batch_Normalization层，**

  实际是对数据进行一定程度的预处理，增大模型的**泛化能力**



## 2-12全连接层

### 什么是全连接层？

* 连接所有特征，将输出的值送给分类器

### 全连接层的一些概念

* 将网络的输出变成一个向量
  * <img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-12将网络输出为一个向量.PNG" alt="3-12将网络输出为一个向量" style="zoom:75%;" />
* 常配合dropout层使用，随机丢弃一些数据防止参数过多产生过拟合问题
* 可以使用卷积来代替全连接
  * 例如：需要将一个特征图转化成512维的向量
    * 方法一：全连接可以通过512个超参数（上面的Y1、Y2）来实现
    * 方法二：卷积可以通过一个H×W的卷积核来进行卷积，并且在卷积过程中不进行padding。我们设置out_channel:512则特征图的大小就会变成n×1×1×512
* 对于输入数据尺度敏感
  * 在全连接层由于输入数据尺度变化则连线的数量也会发生变化导致参数也会发生变化
  * 在参数变化之后，我们去使用全连接层的预训练模型就会出现问题，因为参数数量会不匹配



## 2-13Dropout层

### 什么是Dropout层？

* 在模型训练中，随机的丢弃一些输入值。（将要丢弃输入值的参数值设置为0，让其不起作用，此时对其部分的参数值也不会更新）
* 能够解决过拟合的问题
  * 减少神经元之间的依赖
    * 例如：下图中会随机的丢弃一些神经元来简化网络
    * ![3-13dropout图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-13dropout图.PNG)
  * 取平均的作用（多个不同网络的平均的结果）
    * 对于同一层而言，由于加入了dropout层，所以每次训练时的网络模型都可能不同，但是我们又需要得到一个相同的准确结果，所以最终输出可以看作是多个不同网络平均的结果



## 3-14损失层（1）

* **损失函数**：用来评估模型的预测值和真实值之间的不一致程度
* 损失函数又分为：经验风险最小和结构风险最小
  * 经验风险最小：指的是预测值和真实值之间不一致程度最小
    * 约束函数：交叉熵损失、softmax loss等
  * 结构风险最小：定义了模型的复杂程度越低，模型的结构风险越小，就意味着模型越简单，越不易过拟合
    * 目的是在多组解中找到一个最合适的解，也就是尽量约束解空间，来找到使得经验风险最小的那组最优解。其实约束了解空间会使得模型结构更加的简单，参数更少，从而也会降低过拟合的风险
      * 多组解：在只知道输入和输出的情况下，使得经验风险最小的模型和参数可能有很多个也就是所谓的多组解。【注意】在已经确定了一个模型之后就不会存在多组解了，只会输出该模型下的解（例如在具体的梯度下降运算中只会得到一个满意的值，而不会出现多个值，这是因为梯度下降是一个具体的求解过程，已经加入了许多约束条件（例如在求解w和b的时候因为模型的形式已经被定义，所以解空间其实已经就被约束了一部份））。
    * 约束函数：L0范数、L1范数、L2范数（被称为正则项或者惩罚项）
* 综合考虑经验风险最小和结构风险最小可以得到最优的损失函数如下图：
* ![3-14损失函数](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-14损失函数.PNG)



* **损失层：**定义了使用的损失函数，并且通过最小化损失来驱动网络的训练
  * 前向传播计算网络损失
  * 通过损失函数来进行反向传播来不断调整网络参数，最终得到能够让损失最小化的参数。
  * 对于损失层通常都是定义的经验风险最小，而结构风险最小通常需要对于不同的变量和网络层单独进行约束
    * 例如对卷积层的卷积核进行结构风险最小的约束，那么可以通过对w、b添加L2正则进而实现结构风险最小的约束
  * 分类任务损失：交叉熵损失
  * 回归任务损失：L1损失（差的绝对值的和）、L2损失（平方和——欧氏距离）



## 2-15损失层（2）

* **交叉熵损失**
  * log-likelihood cost（对数似然成本）
    * 似然：已知结果去反推原因（学习参数）
  * 非负性
  * 当真实输出值a与期望值输出y接近时，代价函数接近0（下图是基于二分类的表达式）

<img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-15交叉熵函数表达式.PNG" alt="3-15交叉熵函数表达式" style="zoom: 67%;" />

* **L1、L2、Smooth L1损失**
  * L1 loss = | f(x) - Y |	，其导数为：±f'(x)	——	X≠0时导数绝对值大小不变，且在0处不可导（X=f(x)-Y）
  * L2 loss = | f(x) - Y |^2    ，其导数为：2(f(x)-Y)f'(x)    ——    X接近0导数越来越小，最后在0处导数为0（X=f(x)-Y）
  * Smooth L1损失
    * 是L1和L2的形变，用于SSD和Faster RCNN等网络计算损失
    * 常用于回归问题
    * 在|x|<1的情况下使用L2损失来减缓梯度下降的速度，避免错过最优解；在x的其他情况下使用L1损失，来加快梯度下降速度。表达式如下所示：

<img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-15SmoothL1损失函数表达式.PNG" alt="3-15SmoothL1损失函数表达式" style="zoom:75%;" />



## 3-16卷积神经网络发展历史

### 常见的卷积神经网结构如下图：

<img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-16常见的卷积神经网结构.PNG" alt="3-16常见的卷积神经网结构" style="zoom: 50%;" />



## 3-17LeNet 与 AlexNet —— 卷积神经网如何减少参数量和计算量

### （一）LeNet

* 麻雀虽小五脏俱全（卷积层、下采样层、全连接层、（激活层有无都可）、Soft Max）
  * 1998年，LeCun提出
  * 用于解决手写数字识别
  * MNIST：手写数字识别公开数据集
    * 在实际开发中，一般会通过像caffe、tensorflow这样的框架搭建神将网络，这个时候一般会使用LeNet来完成手写数字识别任务，去验证搭建是否成功 
* 总结：图片通过卷积、池化特征提取之后，再通过FC层（全连接层）将提取的特征值映射到一个概率分布上（例如任务是10分类这个时候FC层长度就是10），最后得到这样一个10维的特征向量之后通过Soft Max将最终的结果映射到0~1之间。
* LeNet基本网络结构图如下(输入了一个手写数字6的灰度图片)：

![3-17LeNet基本网络结构](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-17LeNet基本网络结构.PNG)



### （二）AlexNet

* 2012年，Hinton的学生Alex再寝室用GPU死磕出一个Deep Learning模型，一举拿下图像识别大赛冠军（ILSVRC大赛）

> * AlexNet简易图如下：（图中只列举出来了卷积层）
>
> ![3-17AlexNet简易结构模型](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-17AlexNet简易结构模型.PNG)
>
> * 【模型解析】：经过多个卷积层后进入到全连接层最后通过全连接和softmax层将特征映射到一个1000维的向量上（上图最后一个标示着1000维的层就是fc+softmax）
>   * con(卷积层提取特征)	-	relu(激活层增加网络非线性的表达能力)	-	pooling（下采样层，对图像进行下采样、增大图像感受野、进一步提取图像特征）	-	LRN（Local Response Normalization）（标准化层进行归一化，对数据层进行约束，使得网络更好的收敛）
>   * fc(全连接层，注意参数量极大)    -    relu（增加非线性表达能力）    -    dropout（随机丢弃一些参数）
>   * fc    -    softmax（将特征映射到一个1000维的向量上  ——  实际上就是输入的图像在这1000个类别上的概率分布）
>   * 参数量60M以上
>   * 模型大小>200M



### AlexNet的特点

> * ReLU层增加了网络非线性表达能力
> * Dropout层，防止过拟合
> * 增强数据，减少了过拟合问题
>   * 增强数据：使得训练的数据集比原图多了许多新的样本，减少了过拟合的问题
>     * （1）对图片进行一定比例缩放 Resize
>       （2）对图片进行随机位置的截取
>       （3）对图片进行随机的水平和竖直翻转
>       （4）对图片进行随机角度的旋转
>       其中第一个参数就是随机旋转的角度，比如填入 10，那么每次图片就会在 -10 ~ 10 度之间随机旋转。
>       （5）高斯噪声
>       在图像中随机加入少量的噪声。该方法对防止过拟合比较有效，这会让神经网络不能拟合输入图像的所有特征。
>       （6）对图片进行亮度、对比度和颜色的随机变化
> * 标准化层（local Response Normalization —— 局部相应归一化）



### AlexNet的意义

> * AlexNet证明了通过利用更深的神经网能够提取图像中更加鲁棒的信息，更好的完成图像识别的效果。



## 3-18 ZFNet 与 VggNet —— 卷积神经网如何减少参数量和计算量

### (一)ZFNet

* 在AlexNet的基础上进行细节调整，并取得2013年ILSVRC的冠军
  * 从可视化的角度出发，解释了CNN有非常好性能的原因

### ZFNet与特征可视化

> * 特征可视化图如下：
>
> ![3-18ZFNet可视化过程图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-18ZFNet可视化过程图.PNG)
>
> * 通过观察特征可视化总结出了一些结论
>   * 特征分层次体系结构
>     * 对于卷积神经网，不同层的特征的层次结构非常明显（例如彩色图经过一次浅层卷积得到纹理图（此时特征层次更加的抽象了），对于纹理图再深层卷积之后会得到更加精细的纹理结构图，再经过多次深层次的卷积之后，再经过可视化后就会变得很难通过视觉上去描述这是个什么图，这个时候的特征就成为高层次上的语义特征）
>   * 深层特征更鲁棒
>     * 表现在：输入图像发现一些轻微扰动，则浅层次的特征会发生一些明显的变化，但是更深层次的特征产生的变化越来越小。所以更希望用深层次的特征完成对图像的描述，这样就会对图像的一些轻微扰动和噪声变得不敏感
>   * 深层次的特征更有区分度
>   * 深层次的特征更加难收敛
>     * ResNet可以解决网络变深以后后难以训练和收敛的问题
>   * 等等



### （二）VggNet



> * 由牛津大学计算机视觉组和Google Deepmind共同设计
> * 为了研究网络深度对模型准确度的影响，采用小卷积堆叠的方式搭建整个网络
> * 参数量：138M
> * 模型大小>500M
> * 2014年ILSVRC夺得亚军，但是由于模型提取出来的特征更有实用价值，为后续很多网络所使用
> * 结构图如下：（每个conv之间都会插入激活层和池化层下图未列举）（conv3-64    ——    `3`：3×3的卷积核；`64`：通道数量）

![3-18vggnet简化结构图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-18vggnet简化结构图.PNG)

### VggNet的特点

> * 更深的网络结构，结构更加规整、简单
> * 全部使用3×3的小卷积核（堆叠）和2×2的最大池化层（下采样）
> * 每次池化后Feature Map宽高降低一半，通道数量增加一倍
> * 相比于AlexNet而言，网络层数更多、结构更深、模型参数量更大



### VggNet的意义

> * 证明了更深的网络能够提取更好的特征
> * 成为了后续很多网络的backbone（骨干）
> * 规范化了后续网络的设计思路



## 3-19 GoogleNet / Inception V1

> * **什么是GoogleNet？**
>   * 在设计网络时，不仅强调网络的深度，也会考虑到**网络的宽度**，并将这种结构定义为Inception结构（一种网中网的结构，即原来的节点也是一个网络）
>   * 2014年ILSVRC比赛中夺得冠军，这个model证明了：用更多的卷积网络(宽度)和更深的层次能够得到更好的结构（但是并没有证明浅的层次不能达到这样的效果）
>   * 参数量6.8M
>   * 模型大小50M



> * **GoogleNet的特点**
>
>   * 更深的网络结构
>   * 考虑网络的宽度
>   * 两个LOSS层，降低过拟合的风险
>   * 巧妙利用1×1的卷积核来进行通道降维，减少计算量
>     * 下面这张图是一个Inception结构（GooleNet中最小的结构单元）当然GooleNet中包含多个Inception结构
>
>   ![3-19Inception结构](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-19Inception结构.PNG)



> * **Inception v2 / v3**
>   * 减少了参数量 / 计算量（通过将5×5的卷积核拆分成两个3×3的卷积核等）
>   * 通过拆分大卷积核也增加了卷积的深度，并且可以在每个卷积后面加入一个ReLU激活层可以增加非线性的表达能力
>   * Inception v2 / v3图如下：
>
> <img src="E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-19Inceptionv2_v3.PNG" alt="3-19Inceptionv2_v3" style="zoom: 67%;" />



## 3-20 从卷积的角度出发，如何减少网络中的计算量

* 对大卷积核进行拆分
* 利用stride=2来代替pooling层（减少了当前卷积层的计算量）
* 巧妙利用1×1的卷积核（就像Inception结构一样）



## 3-21 ResNet

> * **ResNet介绍**
>   * 在2015年由何凯明团队提出，引入跳连的结构来防止梯度消失问题，进而可以进一步加大网络深度（这就解决了VggNet网络变深会下降网络性能的问题）
>     * 随着网络变深模型的非线性表达能力也会变得更好但是为什么会出现性能降低的问题？
>       * 主要是因为：参数调节困难（BP算法），网络结构在梯度求解过程采用的是链式求导法则，也就是说进行梯度求解的对象其实是一个复合函数，复合函数进行链式求导法则其实就是`多个导数乘积`假设将结果抽象成`x^n`如果`x<1,n->+∞`那么结果就趋近于`0`——就会产生梯度消失。`x>1,n->+∞`那么结果就趋近于`＋∞`——就会产生梯度爆炸。（ResNet通过跳连能够缓解这样的问题）



> * ResNet跳连结构图：
>
> ![3-21resnet跳连结构图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-21resnet跳连结构图.PNG)
>
> * ResNet网络结构图：
>
> ![3-21resnet网络结构图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-21resnet网络结构图.PNG)
>
> > * 也是采用卷积堆叠的方式，只是核心单元不在是串联的卷积而是跳连结构的单元进行堆叠
> > * conv1：第一层通道数量通常只有3层所以可以采用感受野大的卷积核例如上图采用了7×7的卷积核
> > * 50-layer：50层以上的卷积结构中引入了1×1的卷积核来减少参数量
> > * average pool：最后进行分类时使用一个average pool（pooling层是没有参数的）来代替其他fc层（也就是代替最终输出概率分布前的fc层）（在VggNet中80%的参数都来自fc层）
> > * FLOPs：这里就是计算量



## 3-22 ResNet系列网络



### resnet中的Bottleneck与恒等映射

* **bottleneck：**跳连结构（short-cut）恒等映射，缓解梯度消失问题；

![3-22跳连解决梯度消失图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-22跳连解决梯度消失图.PNG)

> * 在其他的网络结构中x表示输入，F(x)表示输出，在跳连结构中输出为H(x) = F(x) + x如上图左边
>
> * 当F(x)=0时其他的网络会出现梯度消失（怎么产生的见ResNet介绍），此时H(x) = x
>
> * 反向传播解决梯度消失问题
>
>   H(x) = F(x) + x
>
>   ![3-22反向传播解决梯度消失问题一](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-22反向传播解决梯度消失问题一.png)
>
>   输入是x；
>   F(x)相当于residual，它只是普通神经网络的正向传播；
>   输出是这两部分的加和H(x) = F(x)（就是residual） + x（就是shortcut，此代码shortcut部分做了一次卷积，也可以不做）；
>   之所以可以避免梯度消失问题，是因为反向传播时，ε 代表的是 loss 方程，由链式求导法得：
>
>   ![3-22反向传播解决梯度消失问题二](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-22反向传播解决梯度消失问题二.png)
>
>   可以看出，反向传播的梯度由2项组成的：
>
>   对x的直接映射，梯度为1；
>   通过多层普通神经网络映射结果为：F(x)；
>   即使新增的多层神经网络的梯度为0，那么输出结果也不会比传播前的x更差。同时也避免了梯度消失问题。（原文链接：https://blog.csdn.net/qq_32172681/article/details/100177636）



### ResNet中的BatchNorm

> * 对每个卷积之后都会配合一个BN层
> * 对数据的scale和分布进行约束
> * 简单的正则化，提高网络抗过拟合能力



### resnet的设计特点

> * 核心单元（bottleneck）简单堆叠
> * 跳连结构解决网络梯度消失
> * Average Pooling层代替FC层
> * BN层加快了训练模型的速度和收敛时的稳定性
> * 加大网络深度提高了模型特征提取的能力



### resnet变种网络结构

![3-22resnet变种网络](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-22resnet变种网络.PNG)



## 3-23网络性能计算量对比

![3-23卷积神经网络结构对比](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-23卷积神经网络结构对比.PNG)





## 3-24 轻量卷积神经网络 --SqueezeNet

* 参数更少
* 计算量更少
* 功耗更低为了使模型能更好运用在移动端、嵌入式平台

### 轻量级卷积神经网络有哪些

> * SqueezeNet
> * MobileNet v1/v2
> * ShuffleNet v1/v2
> * Xception

### SqueezeNet

* ICLR-2017，作者分别是Berkeley 和 Stanford
  * 提出了Fire Module（SqueezeNet的基本单元），由两部分组成：squeeze层 + Expand层
    * squeeze层：通过1×1的卷积核来降低通道数量
    * Expand层：通过1×1的卷积核还有3×3的卷积核提取特征值

### SqueezNet特点

> * 1×1卷积核减少计算量
> * 不同size的卷积核，类似Inception
> * deep compression技术压缩模型

### SqueezNet实验比较

![3-24squeezenet实验比较](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-24squeezenet实验比较.PNG)

> * SqueezeNet对32bit的浮点数进行两种不同参数量化成8bit和6bit的定点数，将模型中的参数转化成8bit或者6bit的方式进行表示



## 3-25 MobileNet

* 由Google团队提出，并发表于CVPR-2017

  * Depth - wise Separable Convolution（深度分组卷积）的卷积方式代替传统的卷积方式，以达到减小网络权值参数的目的

  ![3-25MobileNet分组卷积图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-25MobileNet分组卷积图.PNG)

### MobileNet设计思想

> * 对标准的卷积拆分，拆分成两组卷积
>   * depth-wise convolution：将每一个in_channel（输入的feature map）都作为一个组，每一组包括一个feature map，然后进行组内卷积（每一组学习一个卷积核，也就是说输入多少个channel就会输出多少个channel），这个过程称为深度卷积（Depth-wise Convolution）
>     * 【注意】在进行深度卷积我们是在每一个小组内进行的，所以我们只能学到每一个feature map内部空间上的信息 { 而卷积不仅要得到每个特征图内部空间的信息还要得到各个特征图之间的联系）（就像传统的卷积运算是没有按照通道分组操作，直接对输入的图像的feature map和通道一起进行卷积操作，所以会同时得到特征图内部的信息和特征图之间的信息（对图像通道进行卷积得到）}
>   * point-wise convolution：通过点卷积（point-wise convolution）学习channel（特征图）之间的信息，也就是对通道做卷积。实际上点卷积就是1×1的卷积核
> * 将深度卷积和点卷积结合起来就是所谓的深度可分离卷积
> * 设计思想图如下：（M是通道数量）
>
> ![3-25MobileNet网络设计思想](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-25MobileNet网络设计思想.PNG)
>
> 

### MobileNet计算量与传统计算量之比

![3-25MobileNet计算量之比](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-25MobileNet计算量之比.PNG)

* 传统计算量是分母，深度卷积计算量是分子中“+”的左半部分，点卷积是“+”的右半部分
* D_k^2：卷积核的大小；
* M：in_channel；
* N：out_channel
* D_F^2：输入的特征图的大小
* D_k^2：最小是1×1的卷积核的大小，N：通常都会大于1。所以分子小于分母，也就是说MobileNet计算量减小了

### MobileNet-v1 实验比较

![3-25mobilenet_v1_实验比较](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-25mobilenet_v1_实验比较.PNG)

得出结论：通过深度可分离卷积对标准卷积进行替换，进而实现模型轻量化的转变，通常在精度上的变化比较小，但是参数量和计算量（Mult-Adds）变化比较明显。

### MobileNet-v2

> * Inverted residuals（倒置残差）
>
>   * 倒置：主要体现在下图中第一个红色的PW(点卷积)不是为了减少通道的数量（ResNet是为了减少）而是为了增加通道的数量
>
>   * 残差：残差在数理统计中是指实际观察值与估计值（拟合值）之间的差
>
> * Linear bottlenecks（线性的结构单元）
>
>   * 如下图
>   * ![3-25mobilenet线性结构单元图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\DeepLearning\image\3-25mobilenet线性结构单元图.PNG)
>   * 在v2中由于前面多次使用ReLU激活层（MAX（x,0））虽然增加了非线性表达能力，但破坏了数据结构，所以在最后使用Linear来减少对数据的破坏确保对性能的提升

### MobileNet VS ResNet

> * 如下图：
>
> ![3-25mobilenet_vs_resnet](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-25mobilenet_vs_resnet.PNG)
>
> * ResNet中3×3的卷积是传统的卷积运算，第一个1×1的卷积是为了将通道数量减少（n --> 0.25n）
> * MoubileNet-v2中的1×1的卷积是为了增加通道的数量（n --> 6n），3×3的卷积是拆分后的深度卷积非传统卷积

### MobileNet总结

* 通过标准卷积拆分可以减少计算量进而减少模型的大小



## 3-26 ShuffleNet V1

* 由旷视科技提出的一种轻量型卷积网络
  * 深度卷积来代替标准卷积
  * 分组卷积+通道shuffle
* 下面是ShuffleNet的结构单元图

![3-26ShuffleNet_v1结构单元图](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-26ShuffleNet_v1结构单元图.PNG)

* 在（b）单元中无下采样，先通过一个分组卷积（GConv）-->进入channel shuffle-->进入深度卷积-->进入分组卷积

* 在（c）中加入了步长为2的下采样，下采样主要是在深度卷积时完成。因为在卷积中完成了一个下采样所以在输入数据中也要加入一个下采样层（图c中的左分支）

  > * 如何对通道进行打乱（channel Shuffle）：
  >
  > ![3-26对通道进行打乱](E:\MySoftware\LearningRelated\Markdown\TheDocument\MyNotes\毕业设计\TensorFlow实现人脸识别小程序\image\3-26对通道进行打乱.PNG)
  >
  > * 假设有3个组，9个通道，每个组3个通道，那么到了channel shuffle时会按照一定的映射关系来打乱通道，完成channel shuffle

### ShuffleNet VS MobileNet

> 实验比较图：
>
> ![image-20210430203501764](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210430203501764.png)
>
> * （g=3）：分组的数量
> * 在上面可以看到在同等规模下mobilenet的计算量要比shufflenet大，并且错误率也高一些



## 3-27 ShuffleNet V2

* 旷视科技针对ShuffleNet V1改进的轻量型卷积神经网络
* ECCV 2018发布（ECCV--计算机视觉顶会）
* 该模型最大的贡献在解释了如何去设计轻量型卷积网络的几个标准和规范



### 轻量型卷积神经网络设计标准

> * 相同的通道大小，可以最小化内存访问成本（MAC）
>   * 网络的宽度：channel的数量
>   * 之前估算一个模型计算量都是使用“乘加”的方式进行的，并没有考虑内存存取时的计算量
> * 过度的组卷积化会增加MAC
> * 网络碎片化（GoogleNet的多路径结构）会降低并行度
> * 元素级运算不可忽略（下图中add操作）
>   * 例如在跳连结构中最后需要有一个相加的运算，就是对特征图上每个像素点进行加的运算



### ShuffleNet V2 VS ShuffleNet V1

> 如下图：
>
> ![image-20210430205853673](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210430205853673.png)
>
> * 图a,b是V1。c,d是V2
> * V2通过减少分组卷积提高了模型的性能
>   * V2将1×1 GConv --> 1×1Conv
>   * 通过channel split分离通道一部分进行卷积，一部分直接到concat层连接，这样就只有一部分通道进行了卷积，分组数量也减少了
> * 取消了add操作
>   * 减少了元素级运算

### ShuffleNet V2比较图

![image-20210430211010706](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210430211010706.png)



## 3-27 Xception

* 由Google提出，arXiv的V1版本由于2016年10 月公开。
* 同样借鉴了深度卷积的思想，但是又存在差异
  * Xception先采用1×1卷积，再进行主通道卷积；(MobileNet是先通过主通道卷积再进行1×1卷积)
  * Xception再1×1卷积之后会加入ReLU;

### Xception网络结构图

![image-20210430211930119](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210430211930119.png)



## 3-28 多分支的卷积神经网络

### Siamese Net	——	两支的网络

* 孪生网络（输入的图片有两个）
* 利用余弦距离（0~1）或欧几里得公式距离（0~+∞）
* 度量问题
  * 相似度
* 图片：

![image-20210502142527974](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502142527974.png)

> * 图中输入两张图片，输出两张图片之间的关系



### 度量问题

* 分类问题
  * 主要是面向离散的数据（识别猫狗）
* 回归问题
  * 主要面向连续的数据（股价预测）
* 度量问题
  * 相似度
  * 排序问题
    * 例如图像检索：给定一张图片在检索其他图片于给定图片的相似度的问题



### 余弦距离

* 余弦距离，也称为余弦相似度，是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量



### 余弦距离——扩展Loss

都是为了研究人脸识别技术而诞生的：

* Center Loss
* CosFace
* AMSoftMax
* SphereFace
* ArcFace
* CCL



## Triplet Net	——	三支的网络分支

* Anchor（锚示例） + Negative（负示例） + Positive（正示例）
* Anchor + Negative构成了不同类样本对、Anchor + Positive构成了同类样本对
* 网络最终优化的方向：通过优化锚示例与正示例的距离 < 锚示例与负示例的距离（类样本对尽可能的小，不同类样本对尽可能的大）

![image-20210502145112432](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502145112432.png)

> * 下面的公式给出的是Triplet Loss函数（锚示例与正示例的距离 - 锚示例与负示例的距离 + 彼此之间的间隔）
> * 优化目标：Loss函数尽可能的小，要求anchor到负样本的距离与anchor到正样本的距离之差要大于α



### Triplet Net 网络结构

![image-20210502150025699](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502150025699.png)

> * 经过运算将图片转化成三个向量输入计算损失后通过BP优化参数
> * 例如：假设有两个图片，通过TripletNet转化成各自对应的向量后，如果两个图片是同类目标的话，那么转化出来的向量之间的距离就会很小，反之则会很大。



### Triplet Net 网络特点

* 提取Embedding feature
  * 图像通过Teiplet Net 转化成向量，向量本身是有一个判别信息在内可以保证同类信息距离最小，不同类之间距离的信息大
* 细粒度识别任务
  * 可以完成同类目标和不同类目标之间判定
* 正负样本比例失衡    ——    难例挖掘
  * 对于不同类别的样本，在构建样本对的时候，一定是负样本（0）对的数量一定是>>正样本（1）对的数量`0>>1`这个时候正负样本比例严重失衡。
  * 解决上面出现的问题就提出了难例挖掘策略 —— 找到对于网络识别困难的样本（差异性比较小的部分）作为输入，进而可以控制正负样本比例失衡。



## Quadruplet Net

* 相比于Triplet Net多了一张负样本
  * 当前样本 + 一个正样本 + 两个负样本
* 正度样本之间的绝对距离

![image-20210502154555082](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502154555082.png)

> * 上图中左边是Quadruplet Net的loss计算公式，其中公式含义可以参考Triplet Loss的含义（注意：其中第一个括号内起到的是决定作用，第二个括号起到的是辅助作用，所以`α>β`）



## 多任务网络

* 多任务网络的两种结构

![image-20210502155236031](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502155236031.png)

> * 在主干网络上都是共享参数的
> *  左边采用的是多分支输入多分支输出结构，例如：行人检测和人脸识别
> * 右边采用的是单分支输入和多分支输出，根据要求解的不同任务再分出不同的分支，例如：目标检测（同一张图像，经过特征提取之后，分别预测当前图像中目标的位置信息以及目标的类别）
> * 优点
>   * 减少参数量和计算量（特征层共享）
>     * 如果对于当前的多任务网络我们通过三个网络来解决的话对于同一张图片我们就需要提取三次特征，这时计算量有很多都是被浪费掉的，参数量也是更大的
>   * 通过多个loss对整个特则进行调控，这时要考虑到彼此任务之间的关联性，找到一组共同的特征，那么这组特征在多任务上都能表现出较好的性能，这就相当于对于整个解空间做了约束。但是对于多任务而言各个loss之间的协调没有处理好的话，我们通过多任务网络可能会得到一个更加差的结论。



## 卷积神经网络中的Attention机制

* 人类大脑在接受和处理外界信号时的一种机制
  * 例如我们在看paper时不是直接关注的全局的信息而是关注的最先吸引我们注意力的地方

* one-hot分布或者soft的软分布
* soft - attention或者hard - attention



### Attention 实现机制

* 保留所有分量均作加权（即soft attention）
* 在分布中以某种采样策略选取部分分量进行加权（即hard attention）
* 可以对不同的对象进行加权：原图、特征图、空间尺度、通道、特征图上的每个元素、不同历史时刻



### ResNet Attention机制例子

<img src="C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502163335873.png" alt="image-20210502163335873"  />

> * 上半部分就是resnet结构
> * 下半部分就是在计算特征图上每一个点的权值，通过卷积＋反卷积的方式来得到一个与当前特征图大小一样的输出结果，再将输出结果激活（归一到0~1之间），再和特征图进行点乘，再进行相加就完成了对当前特征图的加权。



### SENet Channel的Attention机制例子

<img src="C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502164250204.png" alt="image-20210502164250204"  />

> * 通过运算得到一个C维的特征向量（也就是每个特征图上的权值），然后将权值与特征图点乘，不同的权值与对应的特征图相乘，得到一个新的特征图（上面的彩图 —— 也就是通过Channel Attention之后的特征图）



## 3-30卷积神经网的压缩方法

**学院派 VS 工程派**

* 学院派更加注重模型的精度
* 工程派更加注重模型的速度

**模型压缩是对模型精度和速度上的一种平衡**

* 常见压缩模型
  * 模型剪枝
  * 模型量化/定点化
  * 模型蒸馏



### 模型剪枝

* 除去无意义的权重和激活来减少模型的大小
  * 贡献度排序
  * 去除小贡献度单元
  * 重新fine - tuning

![image-20210502180158148](C:\Users\liukun\AppData\Roaming\Typora\typora-user-images\image-20210502180158148.png)



### 模型剪枝技巧

* 全连接部分通常会存在大量的参数冗余
* 对卷积窗口进行剪枝的方式：可以减少卷积窗口权重，或者直接丢弃掉卷积窗口的某一维度
* 丢弃稀疏的卷积窗口，但这并不会使模型运行速度有数量级的提升
* 首先训练一个较大的神经网络模型，然后再逐步剪枝成小的模型



### 模型量化/定点化

* 减少数据再内存中位数的操作，可以采用8位类型来表示32位类型的浮点（定点化）或者直接训练低于8位的模型，比如：2bit、4bit模型等
  *  减少模型占用的空间和计算算量
  * 对于某些定点运算方式，甚至可以直接消除乘法操作，只做加法操作，某些二值模型，直接使用位操作
  * 代价通常是位数越低，精度下降越明显
* 在tensorflow中，常引入量化层，改变计算图，达到模型量化（输入浮点数经过量化层定点化后再运算最后输出层再变回原来的浮点数）



### 知识蒸馏

* 采用一个大的、复杂的网络模型来指导一个小的、精简之后的网络模型进行模型训练和学习



